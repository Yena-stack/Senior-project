# -*- coding: utf-8 -*-
"""manually_preprocessed

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vy2rZYdFZHPuV_bRYeSedDvzcaLbi68t
"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="7WLwYOvv8HBpfBblxXkO")
project = rf.workspace("joseph-nelson").project("pistols")
dataset = project.version(1).download("yolov5")

import cv2
import os

# Set the paths to the downloaded dataset images and annotations
image_dir = "/content/Pistols-1/export/images"
annotation_dir = "/content/Pistols-1/export/labels"

# Create a directory to store the preprocessed images
preprocessed_dir = "/content/Pistols-1/export/preprocessed"
os.makedirs(preprocessed_dir, exist_ok=True)

# Define the desired crop dimensions
crop_width = 200
crop_height = 200

# Iterate through each image file in the dataset
for image_file in os.listdir(image_dir):
    image_path = os.path.join(image_dir, image_file)
    annotation_file = image_file.replace(".jpg", ".xml")
    annotation_path = os.path.join(annotation_dir, annotation_file)
    
    # Load the image
    image = cv2.imread(image_path)
    
    # Get the image dimensions
    image_height, image_width, _ = image.shape
    
    # Calculate the crop coordinates
    x_start = (image_width - crop_width) // 2
    y_start = (image_height - crop_height) // 2
    x_end = x_start + crop_width
    y_end = y_start + crop_height
    
    # Perform cropping on the image
    cropped_image = image[y_start:y_end, x_start:x_end]
    
    # Save the preprocessed image
    preprocessed_path = os.path.join(preprocessed_dir, image_file)
    cv2.imwrite(preprocessed_path, cropped_image)

!pip install ultralytics
from ultralytics import YOLO

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone https://github.com/ultralytics/yolov5.git

# Commented out IPython magic to ensure Python compatibility.
# %cat /content/Pistols-1/data.yaml

# Commented out IPython magic to ensure Python compatibility.
# %cat /content/Pistols-1/data.yaml

# Commented out IPython magic to ensure Python compatibility.
# %cd /
from glob import glob

img_list = glob('/content/Pistols-1/export/preprocessed/*.jpg')
print(len(img_list))

from sklearn.model_selection import train_test_split

train_img_list, val_img_list = train_test_split(img_list, test_size=0.2, random_state = 2000)

print(len(train_img_list), len(val_img_list))

with open('/content/train.txt', 'w') as f:
  f.write('\n'.join(train_img_list) + '\n')

with open('/content/val.txt', 'w') as f:
  f.write('\n'.join(val_img_list) + '\n')

import yaml

with open('/content/Pistols-1/data.yaml', 'r') as f:
  data = yaml.safe_load(f)


print(data)
data['train'] = '/content/train.txt'
data['val'] = '/content/val.txt'

with open('/content/data.yaml', 'w') as f:
  yaml.dump(data, f)

print(data)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!python "/content/yolov5/train.py" --img 416 --batch 8 --epochs 50 --data data.yaml --cfg ."/yolov5/models/yolov5s.yaml" --weights yolov5s.pt --name "/yolov5/result/gun_yolov5s_results_preprocessed"

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir /content/yolov5/runs

from IPython.display import Image
import os
val_img_path = val_img_list[0]
!python detect.py --weights /content/runs/train/gun_yolov5s_results/weights/best.pt --img 416 --conf 0.5 source "{val_img_path}"

! pip install imageAI
! pip install opencv-python
! pip install Pillow

from imageai.Detection import VideoObjectDetection

vid_obj_detect = VideoObjectDetection()

vid_obj_detect.setModelTypeAsYOLOv3()

vid_obj_detect.setModelPath(r"users/")
vid_obj_detect.loadModel()